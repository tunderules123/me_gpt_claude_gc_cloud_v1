import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import { OpenAI } from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import { Author, Msg, SendRequest, SendResponse, HistoryResponse } from './types';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;
const TIMEOUT_MS = parseInt(process.env.TIMEOUT_MS || '20000');
const RETRIES = parseInt(process.env.RETRIES || '2');

// Initialize LLM clients
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

console.log('Anthropic client initialized:', !!anthropic);
console.log('Anthropic messages object:', !!anthropic?.messages);
console.log('Anthropic messages create method:', typeof anthropic?.messages?.create);

// In-memory history
let history: Msg[] = [];

app.use(cors());
app.use(express.json());

// Helper functions
function generateId(): string {
  return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
}

function cleanSpeakerLabels(content: string): string {
  // Remove any speaker labels that might have been generated by the model
  return content.replace(/^\[SPEAKER:\s*[^\]]*\]\s*/i, '').trim();
}

function createSpeakerLabeledHistory(history: Msg[]): Array<{ role: "user" | "assistant"; content: string }> {
  return history.map(msg => ({
    role: msg.role,
    content: msg.role === "user" 
      ? `[SPEAKER: User] ${msg.content}`
      : `[SPEAKER: ${msg.author === "gpt" ? "GPT" : "Claude"}] ${msg.content}`
  }));
}

async function callOpenAI(messages: Array<{ role: "user" | "assistant"; content: string }>, retries = RETRIES): Promise<string> {
  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      const completion = await openai.chat.completions.create({
        model: "gpt-4",
        messages,
        max_tokens: 1000,
        temperature: 0.7,
      });
      
      return completion.choices[0]?.message?.content || "No response from GPT";
    } catch (error: any) {
      if (attempt === retries) {
        throw new Error(`OpenAI error after ${retries + 1} attempts: ${error.message}`);
      }
      // Exponential backoff
      await new Promise(resolve => setTimeout(resolve, Math.pow(2, attempt) * 1000));
    }
  }
  throw new Error("OpenAI call failed");
}

async function callAnthropic(messages: Array<{ role: "user" | "assistant"; content: string }>, retries = RETRIES): Promise<string> {
  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      // First try role-faithful approach
      const response = await anthropic.messages.create({
        model: "claude-3-haiku-20240307",
        max_tokens: 1000,
        messages,
      });
      
      const content = response.content[0];
      if (content.type === 'text') {
        return content.text;
      }
      return "No text response from Claude";
      
    } catch (error: any) {
      // If alternation error, try compatibility mapping
      if (error.message?.includes("alternation") && attempt === 0) {
        try {
          const compatMessages = messages.map(msg => {
            // Rewrite only GPT's assistant messages as user, preserve Claude's as assistant
            if (msg.role === "assistant" && msg.content.includes("[SPEAKER: GPT]")) {
              return { role: "user" as const, content: msg.content };
            }
            return msg;
          });
          
          const response = await anthropic.messages.create({
            model: "claude-3-haiku-20240307",
            max_tokens: 1000,
            messages: compatMessages,
          });
          
          const content = response.content[0];
          if (content.type === 'text') {
            return content.text;
          }
          return "No text response from Claude";
        } catch (compatError: any) {
          if (attempt === retries) {
            throw new Error(`Anthropic error (compat retry failed): ${compatError.message}`);
          }
        }
      } else if (attempt === retries) {
        throw new Error(`Anthropic error after ${retries + 1} attempts: ${error.message}`);
      }
      
      // Exponential backoff
      await new Promise(resolve => setTimeout(resolve, Math.pow(2, attempt) * 1000));
    }
  }
  throw new Error("Anthropic call failed");
}

// Routes
app.get('/history', (req, res) => {
  const response: HistoryResponse = { history };
  res.json(response);
});

app.post('/send', async (req, res) => {
  try {
    const { content, tags }: SendRequest = req.body;
    
    if (!content?.trim()) {
      return res.status(400).json({ error: "Content is required" });
    }
    
    if (!Array.isArray(tags) || tags.length === 0) {
      return res.status(400).json({ error: "Tags array is required" });
    }
    
    // Add user message to history
    const userMessage: Msg = {
      id: generateId(),
      author: "user",
      role: "user",
      content: content.trim(),
      ts: Date.now()
    };
    
    history.push(userMessage);
    
    // Prepare conversation context with speaker labels
    const contextMessages = createSpeakerLabeledHistory(history);
    
    const replies: Array<{ id: string; author: Author; content: string; ts: number }> = [];
    
    // Process each tag in order
    for (const tag of tags) {
      try {
        let response: string;
        let author: Author;
        
        if (tag === "@gpt") {
          response = await Promise.race([
            callOpenAI(contextMessages),
            new Promise<never>((_, reject) => 
              setTimeout(() => reject(new Error(`timeout after ${TIMEOUT_MS}ms`)), TIMEOUT_MS)
            )
          ]);
          author = "gpt";
        } else if (tag === "@claude") {
          response = await Promise.race([
            callAnthropic(contextMessages),
            new Promise<never>((_, reject) => 
              setTimeout(() => reject(new Error(`timeout after ${TIMEOUT_MS}ms`)), TIMEOUT_MS)
            )
          ]);
          author = "claude";
        } else {
          throw new Error(`Unknown tag: ${tag}`);
        }
        
        const cleanedResponse = cleanSpeakerLabels(response);
        
        const replyMsg: Msg = {
          id: generateId(),
          author,
          role: "assistant",
          content: cleanedResponse,
          ts: Date.now()
        };
        
        history.push(replyMsg);
        replies.push({
          id: replyMsg.id,
          author: replyMsg.author,
          content: replyMsg.content,
          ts: replyMsg.ts
        });
        
        // Update context for next model
        contextMessages.push({
          role: "assistant",
          content: `[SPEAKER: ${author === "gpt" ? "GPT" : "Claude"}] ${response}`
        });
        
      } catch (error: any) {
        // Create error message for this specific model
        const errorAuthor: Author = tag === "@gpt" ? "gpt" : "claude";
        const errorMsg = `(error from ${errorAuthor === "gpt" ? "GPT" : "Claude"}: ${error.message})`;
        
        const errorReply = {
          id: generateId(),
          author: errorAuthor,
          content: errorMsg,
          ts: Date.now()
        };
        
        replies.push(errorReply);
        
        // Don't add error messages to conversation history
        // Continue with next model
      }
    }
    
    const response: SendResponse = {
      ok: true,
      userMessageId: userMessage.id,
      replies
    };
    
    res.json(response);
    
  } catch (error: any) {
    console.error('Send error:', error);
    res.status(500).json({ error: error.message });
  }
});

app.post('/reset', (req, res) => {
  history = [];
  res.json({ ok: true });
});

app.listen(PORT, '0.0.0.0', () => {
  console.log(`Server running on port ${PORT}`);
  console.log(`OpenAI API Key: ${process.env.OPENAI_API_KEY ? 'Set' : 'Missing'}`);
  console.log(`Anthropic API Key: ${process.env.ANTHROPIC_API_KEY ? 'Set' : 'Missing'}`);
});